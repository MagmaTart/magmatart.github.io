---
layout: article
title:  "KL Divergence (쿨백-라이블러 발산)"
date:   2017-12-04 12:00:00 -0400
modify_date: 2017-12-04 12:00:00 -0400
tags:
- Machine Learning
- Deep Learning
category: 
- Development
use_math: true
---

GAN을 이해하기 위해 KL Divergence를 먼저 간단히 정리해봅니다.

<!--more-->
-----
GAN을 공부하다가 수식들에 막혀 답답하던 중에, 차라리 그 내부의 요소들을 하나하나 알아보고 가는게 좋겠다고 생각했습니다. 그래서 오늘은 __KL Divergence(쿨백-라이블러 발산)__ 에 대해서 정리해보았습니다.

KL Divergence는 간단히 말해 __두 확률분포의 차이__ 를 계산합니다. 정확히 말하자면, 어떤 확률분포 대신 유사한 모양을 가진 다른 확률분포를 사용해 샘플링을 진행할 떄의 __정보 엔트로피 차이를 계산__ 합니다. 따라서 KL Divergence가 0이면, 두 확률분포가 동일하다는 것을 의미합니다.

두 확률변수에 대한 확률분포인 $$P$$, $$Q$$가 있을 때, 두 분포의 KL Divergence는 다음과 같이 씁니다.

$$D_\text{KL}(P \| Q)$$

$$P$$와 $$Q$$가 연속확률변수의 확률분포일 때, KL Divergence는 다음과 같이 정의됩니다.

$$D_\text{KL}(P \| Q) = \int^{\infty}_{-\infty} p(x) \log \frac{p(x)}{q(x)}dx$$

$$p$$와 $$q$$는 각각 확률분포 $$P$$와 $$Q$$의 확률밀도함수입니다. 식은 확률분포 $$P$$ 대신 $$Q$$를 사용하여 샘플링했을 때, 모든 확률변수에 대해서 정보 엔트로피의 적분을 구하고 있습니다. 분포의 모든 구간에서의 정보 엔트로피 차를 구한다고 보시면 됩니다.

$$P$$와 $$Q$$가 이산확률변수의 분포라면, 다음과 같이 정의됩니다. 실제로 딥러닝에서 KL Divergence를 사용할 때는 대부분 이 경우죠.

$$D_\text{KL}(P \| Q) = \sum_i P(i) \log \frac{P(i)}{Q(i)}$$

이산확률변수이므로 확률밀도함수를 사용하지 않고, 확률분포에서 값을 샘플링했을 경우를 보고 있습니다. 이것도 적분의 모양과 마찬가지입니다. 확률분포 $$P$$를 사용했을 때의 정보 엔트로피와 $$P$$ 대신 $$Q$$를 사용했을 때의 정보 엔트로피 차이를 구하고 있습니다.

정의와 식을 보면 아실 수 있듯이, 두 확률분포가 완벽히 동일하면 KL Divergence는 0이 됩니다. 그래서 GAN의 학습에 KL Divergence가 사용되는 것이었습니다. Cross Entropy(교차 엔트로피)의 정의에도 KL Divergence가 사용되는데, 이는 차후에 따로 글을 써보도록 하겠습니다.