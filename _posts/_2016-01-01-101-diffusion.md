---
layout: article
title:  "High-Resolution Image Synthesis with Latent Diffusion Models"
date:   2016-01-01 12:00:00 -0400
modify_date: 2016-01-01 12:00:00 -0400
tags:
- Paper Reading
- Deep Learning
- Generative Models
category: 
- Deep Learning
use_math: true
---

유전 알고리즘에 대해 간단히 알아봅니다.

<!--more-->
-----
### Introduction
이미지 핮성 프로세스를 Denoising Autoencoder의 연속으로 만들어 SOTA 모델을 만들어냈다. 추가로, 그 과정은 재학습 없이도 이미지 생성에 대해 가이드를 주는 것을 가능하게 한다. 이 모댈은 Diffusion Models (DMs) 라고 한다.
그러나 Pixel Space에서 DM을 돌리는건 매우 큰 컴퓨팅 자원이 들어가기 떄문에 최적화가 필요했다. 제한적인 컴퓨팅 자원에서 DM을 학습하고 실행하기 위해 Latent Space에 DM을 적용하는 방법을 제안한다.

핵심은 - Diffusion Model을 Low Computational Cost로 돌리는 방법을 찾는 것

### Method
#### Diffusion Models
고화질 이미지 합성을 위해 DM의 Computational Cost를 낮추기 위해서, DM이 이미지에서 지역적으로 관련성이 없는 디테일들을 수지할 수 있도록 하는 Loss Terms를 추가해야 한다. (Undersampling corresponding loss terms) 근데 그 Loss 또한 픽셀 스페이스에서 계산되기 때문에 Computational Cost를 많이 먹는다.
이 단점을 우회하기 위해 Generative learning phase의 압축 과정을 명시적으로 분리하는 방법을 제안한다. 이것을 구현하기 위해 Autoencoding 모델이 Image Space와 지역적으로 관련이 있는 Space를 학습하도록 설계한다.
이렇게 하면, (1) 고차원의 Image Space를 벗어나기 때문에 DM의 Computational Cost가 줄어든다. 샘플링을 Low-Dimension Space에서 하기 때문에 (2) UNet 아키텍처에서 물려받은 DM의 Inductive Bias를 활용하여 공간 구조가 있는 데이터에 특히 효과적이며, 따라서 이전 접근 방식에서 요구되는 공격적이고 품질을 저하시키는 압축 수준의 필요성을 완화한다. (3) General Purpose의 Latent Space 모델을 학습할 수 있다. 뒤에 다른 Task를 푸는 모델을 붙일 수 있도록 한다.