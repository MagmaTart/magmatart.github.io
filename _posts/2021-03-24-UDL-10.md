---
layout: article
title:  "[딥러닝 알아듣기] 3.1. 딥 러닝 문제의 개요와 종류"
date:   2021-03-24 12:00:00 -0400
modify_date: 2021-03-24 12:00:00 -0400
tags:
- 딥러닝 알아듣기
- 딥러닝
- Machine Learning
- Deep Learning
category: 
- series
use_math: true
---

"딥러닝 알아듣기" 시리즈는 딥러닝의 기초 지식을 저만의 방식으로 쉽게 풀어내는 시리즈입니다.
이번 챕터에서는 딥 러닝으로 풀고자 하는 문제들의 종류를 살펴봅니다.

<!--more-->
-----
이번 챕터에서는 딥 러닝으로 풀고자 하는 대표적인 문제들을 간단히 살펴보고, 딥 러닝 모델 학습의 전반적인 흐름을 이해해보자. 문제를 풀어내려면 먼저 그 문제의 특성을 이해하고, 접근 방법을 찾아내는 것이 우선이다. 딥 러닝이 어떤 문제에 어떠한 방식으로 활용되는지 먼저 알아보면, 새로운 문제에 부딪혔을 때 어떠한 방법으로 접근해서 문제를 풀어내야 할 지 떠올리기 수월할 것이다.

## 3.1.1. 문제의 성격에 따른 분류
딥 러닝으로 풀 수 있는 문제는 무궁무진하게 많다. 수 많은 데이터 안에서 일련의 특징을 파악해야 하는 모든 작업에 딥 러닝이 활용될 수 있다. 어떤 문제와 데이터 위에서 딥 러닝을 적용하는지에 따라 천차만별이겠지만, 문제의 성격에 따라 나누어 보면 대강 아래와 같은 문제들을 풀어내는 경우가 많다.

- 회귀(Regression) 문제
- 분류(Classification) 문제
- 군집화(Clustering) 문제
- 생성(Generation) 문제
- 두 가지 이상의 문제가 결합된 문제

딥 러닝이 풀고자 하는 문제의 종류는 수없이 많지만, 보통의 경우 넓게 위의 네 가지 문제로 분류할 수 있다. 딥 러닝을 공부하는 과정에서 가장 흔히 만날 수 있는 문제들이기 때문에 확실히 이해하고 넘어가는 것이 중요하다. 각각 어떤 종류의 문제인지 간단히 살펴보도록 하자.

### 회귀(Regression) 문제
회귀 문제는 간단히 말해 데이터 속에서 __함수__ 를 찾는 문제다. 딥 러닝으로 풀 경우, 입력 데이터와 출력 데이터의 관계를 가장 __정확히__ 표현하는 모델을 학습시키는 문제가 된다. 입력 데이터와 출력 데이터 사이의 관계를 가장 잘 나타낼 수 있는 모델을 찾아내서, 모델이 전혀 보지 못했던 입력에 대해서도 기존 데이터들의 경향과 최대한으로 유사한 출력을 만들어내도록 하는 것이 목표다.

말로만 하면 이해가 어려우니 간단한 예시를 하나 들어보자. 필자는 자취를 하기 위해 서울에 방을 잡으려고 한다. 아무 정보도 없이 무작정 방을 구하러 다닐 수는 없으니 몇 가지 기준을 이용해 방을 구하고자 하는 동네의 부동산 시세를 알아보고 싶다. 실제로 집을 구할 때는 훨씬 다양한 사항이 고려되어야 하겠지만, 지금은 예시를 들기 위함일 뿐이니 간단하게 알아보려고 한다. __집의 넓이__ 에 따른 __월세 가격__ 데이터를 모아보자. 아래에 모은 데이터는 예시일 뿐이다. 실제 시세와는 큰 차이가 있다.

| 면적 | 월세 |
| :--: | :--: |
|  20  |  25  |
|  24  |  27  |
|  26  |  29  |
|  31  |  35  |
|  40  |  40  |
|  57  |  57  |

경험 상 집의 면적이 넓어질수록 월세가 비싸지는 경향이 있다. 위와 같은 데이터를 충분히 많이 수집한다면 집의 면적과 월세 사이의 상관 관계를 어느 정도 예측할 수 있을 것이다.

이 관계를 예측하기 위해 딥 러닝을 사용해보자. 집의 면적 데이터를 입력으로 받아서 예상되는 월세를 출력으로 내놓는 딥 러닝 모델을 만들 수 있다. 잘 학습된 모델에 필자가 생각한 집의 조건에 맞는 집의 면적을 입력하면, 어느 정도의 월세 지출이 필요할 지 대강 예측할 수 있게 될 것이다. 모델이 입력 데이터에 따라 예상 월세 값을 출력해주는 함수를 찾아낸 것으로 이해할 수 있다.

실제로 앞에서 모은 데이터를 그래프에 직접 그려보자.

<center><img src="/assets/posts/images/UDL10/figure1.png" width=500></center>
<center><그림 1> 집 면적과 월세 데이터</center>

집 면적을 입력으로 받고 월세 값을 출력으로 내놓는 함수를 데이터로부터 찾아낸다면, 대강 다음과 같이 그래프에 표현할 수 있을 것이다.

<center><img src="/assets/posts/images/UDL10/figure2.png" width=500></center>
<center><그림 2> 집 면적과 월세 데이터 사이의 관계를 표현하는 함수</center>

집 면적과 월세 데이터가 서로 완벽하게 정비례하지 않으니 모든 데이터와 일치하는 함수를 찾기는 힘들다. 그러나 위의 함수와 같이 데이터의 분포를 __최대한으로 정확히 근사하여__ 표현하는 함수를 찾아낼 수는 있다. 저 함수에 새로운 집 면적 데이터를 입력했을 때, 정확하지는 않지만 시세와 얼추 가까운 월세 값을 얻어낼 수 있을 것이다.

이러한 문제를 __회귀(Regression)__ 문제로 볼 수 있다. 집과 관련된 정보를 입력해 예상되는 월세 값을 찾아냈듯이, 입력 데이터와 출력 데이터 사이의 __상관 관계__ 를 찾아내는 문제를 회귀 문제라고 부른다. 딥 러닝 모델이 기존 데이터들의 경향을 학습해서, 새로운 입력 데이터에 대해 __기존의 경향에 가장 알맞는 출력__ 을 내놓도록 한다. 회귀 모델의 학습을 통해서 각 특징 값에 따라 입력 데이터가 어떻게 분포되어 있는지 이해하는 것이다.

딥 러닝으로 회귀 문제를 풀기 위해 입력 데이터와 그에 맞는 정답 출력 데이터가 나열된 학습 데이터셋을 사용한다. 학습이 진행됨에 따라 모델의 파라미터를 갱신하면서, 모든 학습 데이터셋의 입력에 대해 정답에 가장 가까운 출력을 내놓는 파라미터를 찾는다.

앞서 인공 신경망의 개요를 살펴보며 이야기했듯이, 입력 데이터의 종류가 늘어날 수도 있고 출력 데이터의 종류가 늘어날 수도 있다. 회귀 문제를 풀기 위한 모델을 어떻게 디자인하는지에 따라서 더욱 복잡한 함수를 찾아낼 수도 있을 것이다. 보통 어떠한 __값을 예측__ 하는 문제에 대해 널리 활용된다.

### 분류(Classification) 문제
분류 문제는 입력 데이터가 어떤 __클래스(Class)__ 의 데이터인지 찾아내는 문제이다. 클래스는 분류하는 데이터의 종류를 말한다. 분류 문제는 앞선 챕터에서 간단히 다루어 본 적이 있다. 입력 데이터를 가장 확실하게 구분하는 __결정 경계__ 들을 딥 러닝을 이용해 찾아내는 문제로 이해할 수 있다.

분류 문제도 하나의 간단한 예제를 들어보자. 어떤 음식의 영양소 함량 정보를 입력 데이터로 받아서, 그 음식의 종류가 무엇인지 예측하는 모델을 만들고자 한다. 간단하게 음식의 탄수화물과 단백질 함량을 보고 그 음식이 과자와 고기 둘 중 무엇인지 분류하는 모델로 만들자. 영양소 함량 데이터가 어떻게 분포해 있는지 확인하기 위해 그래프에 먼저 데이터를 그려보자.

<center><img src="/assets/posts/images/UDL10/figure3.png" width=500></center>
<center><그림 3> 영양소 함량에 따른 음식의 분포</center>

앞선 챕터에서 퍼셉트론은 입력 데이터를 0 또는 1로 구분하는 구조라고 이야기했었다. 퍼셉트론과 같이 입력 데이터를 두 개의 클래스 중 하나로 구분하는 문제를 __이중 분류(Binary Classification)__ 문제라고 부른다. 음식의 영양소 함량을 보고 그 음식이 과자인지 고기인지 구분하는 문제도 이중 분류 문제이다. 이중 분류 문제를 푸는 모델은 입력 데이터를 두 개의 클래스로 가장 잘 구분해낼 수 있는 파라미터를 찾는다. 앞서 퍼셉트론이 그러했던 것처럼 두 개의 클래스를 0 또는 1로 두고, 모델의 출력 값이 특정한 임계값을 넘는지 여부에 따라 0 또는 1의 출력을 결정한다. 우리의 예제 상황에서는 과자를 0, 고기를 1로 놓을 수 있다. 어떤 임계값 $$T$$를 설정했을 때, 우리 모델의 출력이 $$T$$보다 작거나 같으면 과자(0), $$T$$보다 크면 고기(1)로 판단하도록 만들면 된다.

데이터의 그래프에서 다시 보자. 다음의 그림에서 중간의 빨간 직선이 모델과 임계값에 따른 결정 경계이다. 이 직선을 기준으로 입력 데이터의 위치가 위에 있는지 아래에 있는지 구분하도록 한다. 머신 러닝 모델을 학습해서, 두 클래스의 데이터들을 가장 확실히 잘 구분하는 결정 경계를 찾는 것이 이중 분류 문제의 목표이다.

<center><img src="/assets/posts/images/UDL10/figure4.png" width=500></center>
<center><그림 4> 과자와 고기를 이중 분류하는 결정 경계</center>

문제 상황을 조금 더 확장해보자. 두 영양소의 함량을 보고 과자와 고기 뿐만 아니라 샌드위치까지 같이 구분해내고 싶다. 여러 개의 클래스를 동시에 구분해내고자 하는 것이다. 이런 문제를 __다중 분류(Multi-class classification)__ 문제라고 한다.

<center><img src="/assets/posts/images/UDL10/figure5.png" width=500></center>
<center><그림 5> 세 개의 클래스로 나뉘는 데이터</center>

하나의 결정 경계로는 당연히 다중 분류를 해낼 수 없다. 두 개의 클래스를 구분하는 직선은 하나만 있으면 되지만, 클래스가 세 개 이상일 경우 직선 하나로는 데이터를 구분할 수 없기 때문이다. 그래서 딥 러닝으로 다중 분류 문제를 풀 때는 여러 개의 이중 분류를 동시에 이용하는 방법으로 접근한다. 과자, 고기, 샌드위치를 구분하는 다중 분류 문제는 아래의 세 가지 이중 분류 문제를 동시에 푸는 것으로 봐도 무방할 것이다.
- 입력 데이터의 클래스가 과자인지 과자가 아닌지 분류
- 입력 데이터의 클래스가 고기인지 고기가 아닌지 분류
- 입력 데이터의 클래스가 샌드위치인지 샌드위치가 아닌지 분류

다음처럼 각각의 결정 경계를 동시에 만들어, 입력 데이터가 동시에 속하는 부분이 어디인지 알아내면 된다.

<center><img src="/assets/posts/images/UDL10/figure6.png" width=900></center>
<center><그림 6> 여러 개의 결정 경계를 동시에 사용하면 다중 분류 문제를 풀 수 있다.</center>

이후 챕터에서 이중 분류와 다중 분류 문제를 푸는 딥 러닝 모델을 같이 학습시켜 볼 것이다.

### 군집화(Clustering) 문제
군집화 문제는 __유사한 특징을 가지는 데이터끼리 묶는__ 문제이다. 군집화 문제의 데이터셋에는 정답 데이터가 없다. 수많은 입력 데이터의 특징을 파악해서 비슷한 데이터끼리 하나의 클래스로 묶는다.

영양소 데이터를 다시 보자. 분류 문제에서는 입력 데이터가 어떤 클래스에 속하는 데이터인지 정답이 존재헀다. 그러나 군집화 문제는 데이터들이 어떤 클래스로 나뉘는지 모른다고 가정한다. 수많은 영양소 데이터는 그저 흩뿌려진 데이터일 뿐이다. 

<center><img src="/assets/posts/images/UDL10/figure7.png" width=500></center>
<center><그림 7> 데이터들의 클래스가 따로 정의되어있지 않다.</center>

그냥 이렇게 데이터를 놓고 보면 데이터가 무엇을 의미하는지 알 수 없다. 데이터의 클래스가 없으니 단순히 종류를 알 수 없는 음식들이 무작위로 널려있는 데이터인 것이다. 이런 데이터의 특징을 이해하기 위해 가장 먼저 적용해볼 수 있는 방법은 __비슷한 데이터끼리 묶어보는 것__ 이다. 위의 그래프 상에서 가까이 모여있는 점(데이터)들끼리 가지고 있는 영양소 함량이 비슷하니 같은 음식이라고 예상할 수 있다. 데이터 내 각각의 특징을 포함한 양이 비슷할수록 같은 종류로 분류될 가능성이 높다고 예측할 수 있는 것이다. 단백질 함량과 탄수화물 함량이 비슷한 두 음식은 같은 종류의 음식일 가능성이 높은 것처럼 말이다.

위의 그래프에서 가까이 모여있는 데이터끼리 묶으면, 대강 아래와 같이 두 개의 집단으로 묶을 수 있다.

<center><img src="/assets/posts/images/UDL10/figure8.png" width=500></center>
<center><그림 8> 특징의 함량이 비슷한 데이터끼리 묶었다.</center>

두 개의 집단이 각각 무슨 음식의 영양소 데이터인지는 아직도 모른다. 그러나 각 집단의 영양소 함유량을 분석하면 어떤 음식이 모인 집단인지 유추할 수 있을 것이다. 이렇게 데이터의 분포 특징을 파악하기 위해 비슷한 데이터끼리 묶는 작업을 __군집화(Clustering)__ 이라고 한다.

앞의 예제처럼 군집화는 무작위로 수집된 방대한 데이터에서 전체적인 분류 특성을 알아내기 위해 사용된다. 흩뿌려진 데이터를 무작정 분석하는 것보다, 비슷한 데이터끼리 먼저 묶어본 후 각 집단의 특징을 파악하는 편이 훨씬 빠르게 데이터를 이해할 수 있는 길이다.

군집화된 결과는 향후 새로운 데이터가 들어왔을 때 그 데이터의 특성을 파악하는 데에 도움을 주기도 한다. 위의 영양소 데이터를 군집화해서 각각의 집단이 어떤 음식인지 대강 파악해놓고 나면, 새로운 음식의 영양소 데이터가 입력되었을 때 어떤 음식일지 비교적 정확한 유추가 가능할 것이다. 해당 음식의 영양소 데이터가 어느 군집에 포함되는지만 파악하면 된다.

### 생성(Generation) 문제
생성 문제는 딥 러닝 모델이 학습한 데이터를 기반으로 __새로운 데이터를 만들어내는__ 문제를 말한다. 생성 문제 또한 학습 시에 정답 데이터가 없다. 그저 수많은 데이터를 넘겨보면서 최대한 기존의 데이터들과 비슷한 형태의 데이터를 스스로 만들어낼 수 있도록 학습한다.

생성 문제 또한 간단한 예를 하나 들어 보자. 필자는 고양이를 너무나 좋아한 나머지 고양이 사진을 만들어주는 딥 러닝 모델을 만들고자 한다. 모델에게 수많은 고양이 사진을 보여주면서 그 사진들과 최대한으로 비슷한 사진을 그려내라고 학습시킨다.  

<center><img src="/assets/posts/images/UDL10/figure9.png" width=500></center>
<center><그림 9> 수많은 고양이 사진을 보여주면 결국 고양이를 그려낼 수 있을 것이다.</center>

처음에는 모델이 정말 무작위의 그림을 그려낸다. 비슷하게 그려야 할 그림을 본 적 없는 상태에서 아무 그림이나 그리라고 지시했기 때문이다. 그러나 고양이의 사진과 비슷하게 그리도록 학습을 거듭하면서, 모델은 고양이 그림 자체의 특징을 알아가기 시작한다. 고양이 사진과 비슷한 그림을 그리려면 사진의 어떤 부분을 어떤 색깔로 칠해가야 하는지 이해하기 시작하는 것이다. 이것 또한 데이터 속에서 특징을 발견하는 과정으로 볼 수 있다. 수많은 고양이 사진이라는 데이터 속에서 고양이의 생김새라는 특징을 발견하는 것이기 때문이다.

생성 문제는 딥 러닝이 가장 널리 활용되고 있는 분야 중 하나이다. 생성 모델은 사진이나 음성, 심지어 동영상과 같이 복잡한 고차원의 데이터를 생성하는 문제에도 많이 사용된다. 직접 그림을 그려내는 모델이라니, 겉으로 보면 정말 신기한 기술이다. 그러나 모델이 그림을 생성하게 되기까지의 과정을 따라가 보면, 데이터의 생성도 결국 데이터의 특징을 이해하는 일의 연장선임을 이해할 수 있다. 따라서 모델이 좋은 품질의 데이터를 생성해내도록 하기 위해서는 데이터의 특징을 이해하는 과정을 자세히 파악할 필요가 있다. 고양이 사진을 그려내는 모델을 만들 때, 고양이의 특징을 최대한 확실하게 이해시켜야 더 예쁜 고양이 그림을 만들어낼 수 있는 것처럼 말이다. 우리는 이후에 사진 생성 모델을 같이 학습해보면서 어떻게 딥 러닝 모델이 복잡한 데이터의 특징을 파악하는지 자세히 알아볼 것이다.

또한 데이터를 생성하는 모델의 발전은 컴퓨팅 기술이 발전하면서 그 속도가 빨라졌다. 이야기했듯이, 이해해야 할 데이터의 특징이 복잡해질수록 딥 러닝 모델의 크기도 같이 커져야 하기 때문이다. 시리즈의 후반부에서는 최근의 생성 모델들이 거대한 컴퓨팅 자원을 활용해서 얼마나 현실과 가까운 데이터를 만들어내는지 직접 눈으로 확인해보도록 하자. 딥 러닝의 힘만큼 가능성이 무궁무진한 분야가 바로 데이터 생성 분야이다.

### 여러 문제가 결합된 문제
최근 딥 러닝이 빠르게 발전하면서, 현실의 다양한 문제 상황을 딥 러닝으로 풀어내려는 시도가 많이 이루어졌다. 현실 세계의 문제들은 분류, 회귀 등의 특정 문제로 단순히 구별되지 않고, 여러 분야의 문제가 결합된 양상을 자주 보인다.

가장 대표적으로, 뒤에 살펴볼 __물체 검출__ 문제가 있다. 말그대로 이미지 안에서 특정 물체의 위치를 찾아내는 문제이다. 예를 들어 이미지 안에서 사과를 찾아야 한다면, 다음과 같은 모습으로 찾아낼 수 있을 것이다.

<center><img src="/assets/posts/images/UDL10/figure10.png" width=500></center>
<center><그림 10> 이미지 내에서 사과를 검출한 결과</center>

많은 경우 사진과 같이 해당 물체를 감싸는 사각형(Box)을 찾아내는 형태로 물체를 검출한다. 이 때, 사과 검출 문제는 다음과 같이 두 개의 세부 문제(Sub-task)로 나눌 수 있다.

- 물체를 감싸는 사각형을 찾아내는 문제
- 해당 사각형 내의 물체가 사과인지 판단하는 문제

이미지 안에는 사과 말고도 수많은 물체들이 존재할 것이다. 어떤 물체던지 모델은 그것을 감싸는 사각형을 그릴 수 있다. 따라서 사각형을 찾아내는 동시에, 그 사각형 내의 물체가 검출해야하는 대상 물체인지 확인하는 작업이 동시에 이루어져야 한다.

그렇다면 물체 검출 모델의 학습 과정을 생각해보자. 먼저 수많은 학습 이미지 데이터가 필요할 것이고, 그 이미지 내에서 찾아내야 할 물체의 사각형 위치와 모양, 그리고 해당 물체의 종류(클래스)가 적힌 레이블(Label)들이 필요하다. 보통 레이블들은 대강 아래와 같이 생겼다.

```
X, Y, Width, Height, Class		# 가로축 위치, 세로축 위치, 너비, 높이, 클래스
120, 265, 60, 68, Apple
135, 117, 47, 50, Apple
32, 36, 44, 110, Banana
268, 194, 56, 131, Banana
```

물체 검출 모델은 이미지를 입력으로 받고, 이미지 안에서 각 물체의 위치와 크기를 사각형으로 예측하는 동시에 해당 물체가 어떤 클래스로 분류되는지 판단한다. 사각형 모양의 예측은 __회귀__ 문제이고, 물체의 클래스 예측은 __분류__ 문제인 것이다. 이미지 데이터를 입력받은 모델은 어떻게든 각 물체의 위치를 (X, Y, Width, Height) 의 포맷으로 출력하고, 이는 회귀 문제로써 학습된다. 또한 각 물체의 클래스 판단은 분류 문제로써 학습된다.

딥 러닝으로 풀고자 하는 문제가 복잡해지고 어려워지면 당연히 여러 문제가 결합된 형태로 나타날 수 밖에 없다. 하나의 새로운 예를 들어 보자. 필자는 어떠한 음식의 영양소 데이터를 받아서, 그것이 어떤 음식인지 분류한 후 그 음식의 사진을 생성하려고 한다. 지방과 단백질보다 탄수화물의 함량이 훨씬 큰 데이터를 입력받으면 쌀밥의 사진을 생성하고, 지방과 단백질의 함량이 동시에 높은 데이터를 입력받으면 고기의 사진을 생성하는 식이다. 이 경우, 문제를 다음처럼 두 개의 문제로 나눠서 생각할 수 있다.

- 입력받은 영양소 데이터로 어떤 음식의 영양소인지 분류하는 문제 (분류 문제)
- 분류 결과 음식의 사진을 생성하는 문제 (생성 문제)

이와 같이, 풀고자 하는 문제가 복잡해지고 인간의 생각과 가까워질수록 여러 문제가 결합되고 복잡해지는 양상을 띈다. 현실 세계의 문제를 풀어내기 시작한 최근의 딥 러닝 모델들 중에는 단일 문제를 푸는 모델을 보기가 힘들 정도이다.

## 3.1.2. 학습 방법에 따른 문제의 분류
우리가 딥 러닝으로 풀게 될 대표적인 문제들을 성격에 따라 분류해 살펴보았다. 위에서는 문제 상황에 따라 구분했지만, 딥 러닝 모델의 학습 방법을 데이터셋과 학습 과정의 특성에 따라서도 구분할 수 있다. 보통 딥 러닝 모델의 학습 방법은 아래의 세 가지로 구분된다.
- 지도학습(Supervised Learning)
- 비지도학습(Unsupervised Learning)
- 강화학습(Reinforcement Learning)

### 지도 학습
먼저 지도 학습은, __데이터와 정답이 같이 존재__ 하는 경우의 딥 러닝 모델 학습 방법론을 이야기한다. 모델의 학습 과정에서 모델에게 입력 데이터를 주고, 해당 데이터의 입력으로 모델이 출력하기를 기대하는 __정답 데이터__ 를 동시에 제공한다. 모델은 어떠한 입력 데이터를 받았을 때, 최대한 정답 데이터와 비슷한 출력 데이터를 만들어내도록 학습된다. 주어진 문제를 먼저 풀게 한 후, 문제의 정답과 비교해서 모델이 앞으로는 덜 틀리도록 학습시키는 것이 마치 시험공부를 하는 학생들 같다. 학생들처럼 정답 데이터의 __지도__, 혹은 __감독__ 을 받는다고 해서 __지도 학습(Supervised Learning)__ 이라고 부른다.

지도 학습 방법론이 사용되는 대표적인 문제로는 회귀 문제와 분류 문제를 들 수 있다. 회귀 문제는 모델이 정답 데이터에 최대한 비슷한 출력을 낼 수 있도록 학습된다. 분류 문제 또한 모델의 분류가 정답 클래스와 최대한 동일해지도록 학습된다. 일반적인 경우 회귀와 분류 문제를 푸는 모델은 정답 데이터가 없으면 학습을 시킬 수 없다. 입력 데이터로부터 어떤 출력을 원하는지 직접 정답을 알려주어야만 한다. 따라서 학습을 위한 데이터에 입력 데이터와 정답 데이터가 동시에 존재해야 한다.

지도 학습은 가장 직관적인 딥 러닝 모델 학습 방법론이지만, 상대적으로 학습 데이터를 모으기 힘들다는 점이 최근에 부각되고 있다. 현실의 문제에 딥 러닝을 적용하려면 점점 더 많은 학습 데이터를 필요로 하는데, 입력 데이터와 정답 데이터를 동시에 다량으로 수집하는 것이 어려운 경우가 많기 때문이다.

### 비지도 학습
비지도 학습은, 지도 학습과 반대로 __정답 데이터가 없는__ 경우의 딥 러닝 모델 학습 방법론을 이야기한다. 지도 학습과 다르게, 딥 러닝 모델은 정답 데이터가 없이 스스로 입력 데이터의 특징을 이해해야 한다. 모델을 가르쳐주는 정답 데이터가 없다는 뜻으로 __비지도__ 학습이라고 부르는 것이다.  수많은 입력 데이터들을 분석하면서 스스로 데이터의 패턴을 찾을 수도 있고, 아예 입력 데이터 자체를 모델 스스로의 정답 데이터로 삼아 학습할 수도 있다. 입력 데이터를 스스로의 정답 데이터로 삼는 학습 방법은 __자기지도 학습(Self-Supervised Learning)__ 이라는 이름으로 불리기도 한다.

군집화 문제와 생성 문제가 대표적인 비지도 학습의 예이다. 군집화는 정답 레이블이 없는 상태로 입력 데이터들의 특징만을 보면서 비슷한 데이터끼리 묶는 문제다. 모델이 수많은 입력 데이터를 분석하면서 나름의 패턴을 찾아내는 것이다. 이 과정에서 정답 데이터가 제공되지 않으므로 비지도 학습 방법에 속한다. 만약 정답 데이터를 주고 데이터를 나누라고 한다면, 지도 학습이 적용되는 분류 문제로 바뀔 것이다.

생성 문제는 생성하고자 하는 종류 데이터의 특징 자체를 모델이 이해하도록 하는 것이다. 보통의 경우 정답 데이터는 따로 제공되지 않고, 모델의 입력 데이터들과 최대한으로 비슷한 데이터를 생성할 수 있도록 학습된다. 앞에서 이야기했던 고양이 사진 생성 모델을 다시 떠올려보자. 학습 과정에서 수많은 고양이 사진들을 입력하면, 모델은 입력된 사진 자체를 생성 목표 이미지로 삼고 입력 이미지들의 특징을 이해하도록 학습된다. 자기지도 학습을 하는 것이다. 정답 데이터를 따로 주지 않았지만, 입력 이미지 내에서 고양이 사진의 특징을 이해했으므로 완전히 새로운 고양이 사진들을 스스로 생성해낼 수 있게 된다.

어떠한 문제를 딥 러닝으로 풀 때 비지도 학습 문제로 접근할 경우, 데이터셋을 모으는 부담감이 상대적으로 줄어든다. 양적인 부담을 말하는 것은 아니다. 지도 학습은 학습을 위해 입력 데이터와 정답 데이터를 동시에 모아야 하지만, 비지도 학습을 시행할 경우 입력 데이터들만 최대한 많이 모으면 되기 때문이다. 딥 러닝 학습 방법론과 학습을 위한 컴퓨터 하드웨어가 동시에 발전하면서, 최근의 딥 러닝은 규모가 곧 무기인 상황이다. 따라서 최근의 흐름은 대부분 비지도 학습 방법론을 활용하면서 최대한으로 큰 모델, 최대한으로 많은 데이터를 추구한다. 데이터셋의 확보가 상대적으로 어려운 지도 학습보다 비지도 학습 방법론이 앞으로도 계속 발전할 것이다. 

### 강화 학습
보통의 경우 머신 러닝 학습의 큰 갈래는 지도 학습과 비지도 학습으로만 나누어지지만, 딥 러닝이 발전하면서 새롭게 떠오른 또 하나의 분야가 바로 __강화 학습__ 이다. 강화 학습은 주어진 __상황__ 에서 최적의 __판단__ 을 내리는 모델을 학습하는 방법론이다. 이 때, 판단의 주체를 __에이전트(Agent)__ 라고 부른다.보통 주변의 상황을 파악해 자신의 행동을 결정하는 인공지능의 학습에 널리 활용된다.

강화학습이 기존의 지도/비지도 학습과 독립된 분야로 인식되는 이유는, 풀고자 하는 문제의 상황 자체가 다르기 때문이다. 지도 학습과 비지도 학습은 주어진 데이터를 최대한 잘 이해하고자 하는 것이 목적이다. 상황 자체가 정적인 상태로 볼 수 있겠다. 그러나 강화 학습은 시시때때로 변화하는 주변 환경(Environment)에 대해 최선의 판단을 내리는 것이 목적이다. 데이터를 이용한다는 점은 동일하나, 그것이 데이터 자체를 이해하기 위한 목적인지, 아니면 기존의 데이터를 기반으로 현재의 상황을 판단하는 것이 목적인지에 따라 문제를 구분할 수 있다. 그래서 게임 인공지능과 같은 분야에 강화 학습이 널리 사용된다. 일반적인 지도 학습 방법론을 적용하면 데이터 활용에 분명한 한계가 있기 때문이다.

강화 학습이 활용되는 인공지능 분야에서는, 원래 유전 알고리즘이나 최적화 이론, 통계학 이론들을 활용한 고전적인 머신 러닝 방법론으로 문제를 풀어내고 있었다. 현재 주변 환경에 대한 에이전트의 다음 행동을 고전적인 방법론으로 결정하고 있었다는 이야기이다. 그러나 딥 러닝이 발전하면서, 현재 상황을 이해하고 행동을 결정하는 과정에 딥 러닝 모델을 활용하려는 시도가 이루어지기 시작했다. 그리고 이는 매우 성공적이었다. 특히 딥 러닝 모델의 힘을 빌려 문제 상황의 규모를 무한정으로 확장할 수 있다는 점이 크게 작용했다. 알고리즘을 복잡하게 만들지 않고도, 모델의 크기를 키워 더욱 복잡한 문제를 풀어낼 수 있기 때문이었다. 그래서 딥 러닝은 강화 학습 분야를 지배하는 방법론이 되었다.

시리즈의 도입부에서 이야기했듯이, 알파고와 같은 인공지능들은 여러 게임에서 이미 인간의 수준을 아득히 뛰어넘은 실력을 보여주고 있다. 모두 딥 러닝을 활용한 강화 학습의 결과이다. 알파고가 현재 바둑판의 상황을 이해하는 과정, 그리고 다음으로 놓을 수의 위치를 결정하는 과정이 모두 딥 러닝 모델의 작품인 것이다.